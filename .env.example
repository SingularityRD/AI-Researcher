# ================ AI-Researcher Configuration ================
# üîí SECURITY: Never commit .env file to git!
# Copy this file: cp .env.example .env
# Then fill in your actual values

# ================ Quick Start Guide ================
# 1. Copy this file: cp .env.example .env
# 2. Choose ONE of the API providers below and set its API key
# 3. Run: make up && make webgui
# 4. Open: http://localhost:7860
# For detailed setup: see SETUP_GUIDE.md

# ================ LLM API Keys (Choose ONE or more) ================

# üåü OPTION 1: Z.AI API (Recommended - GLM-4.6 model)
# Get your API key from: https://api.z.ai/
ZAI_API_KEY=your_zai_api_key_here
ZAI_API_BASE=https://api.z.ai/api/paas/v4

# üåê OPTION 2: OpenRouter (Multi-model support)
# Get your API key from: https://openrouter.ai/keys
# Supports: Google Gemini, Anthropic Claude, OpenAI GPT, Meta Llama, etc.
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# ü§ñ OPTION 3: OpenAI (GPT-4, GPT-4o, o1, etc.)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE=https://api.openai.com/v1

# üß† OPTION 4: Anthropic Claude (Claude 3.5 Sonnet, Opus, etc.)
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_API_BASE=https://api.anthropic.com

# üîç OPTION 5: DeepSeek (DeepSeek V2, DeepSeek Coder, etc.)
# Get your API key from: https://platform.deepseek.com/
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_API_BASE=https://api.deepseek.com/v1

# ================ Model Configuration ================
# Main model for research tasks
# Examples for Z.AI:
#   glm-4.6            (Z.AI's GLM-4.6 model)
# Examples for OpenRouter:
#   openrouter/google/gemini-2.5-pro-preview-05-20
#   openrouter/anthropic/claude-3.5-sonnet
#   openrouter/openai/gpt-4o-2024-08-06
# Examples for direct providers:
#   gpt-4o-2024-08-06  (OpenAI)
#   claude-3-5-sonnet-20241022  (Anthropic)
#   deepseek-chat      (DeepSeek)
COMPLETION_MODEL=glm-4.6

# Cheaper model for quick tasks
# Examples:
#   glm-4-flashx       (Z.AI faster variant)
#   openrouter/google/gemini-2.5-flash-preview-05-20
#   gpt-4o-mini
#   claude-3-5-haiku-20241022
CHEEP_MODEL=glm-4-flashx

# ================ Container Configuration ================
# Docker container settings
DOCKER_WORKPLACE_NAME=workplace_paper
BASE_IMAGES=tjbtech1/airesearcher:v1
CONTAINER_NAME=paper_eval
WORKPLACE_NAME=workplace
CACHE_PATH=cache
PLATFORM=linux/amd64

# Port configuration
PORT=7020
WEBGUI_PORT=7860

# GPU Configuration
# Options:
#   '"device=0"'       # Use first GPU
#   '"device=0,1"'     # Use first and second GPU
#   '"all"'            # Use all GPUs
#   None               # No GPU (CPU only)
GPUS='"device=0"'

# ================ Task Configuration ================
# Research category (see benchmark/final/ for options)
# Options: diffu_flow, gnn, reasoning, recommendation, vq
CATEGORY=vq

# Instance ID (see benchmark/final/{CATEGORY}/ for available instances)
# Examples:
#   vq: one_layer_vq, rotation_vq, fsq
#   gnn: gnn_nodeformer, gnn_difformer
#   recommendation: hgcl, dccf
INSTANCE_ID=one_layer_vq

# Task level
# Options:
#   task1: Detailed Idea Description (you provide the idea)
#   task2: Reference-Based Ideation (AI generates idea from papers)
TASK_LEVEL=task1

# Maximum iteration times for refinement (0 = no iterations, 3 = recommended)
MAX_ITER_TIMES=0

# ================ GitHub Configuration (Optional) ================
# For code search and cloning private repos
# Get token from: https://github.com/settings/tokens
GITHUB_AI_TOKEN=your_github_token_here

# ================ Proxy Configuration (Optional) ================
# Uncomment and set if you need to use a proxy
# HTTPS_PROXY=http://your-proxy:port
# HTTP_PROXY=http://your-proxy:port
# NO_PROXY=localhost,127.0.0.1,0.0.0.0

# ================ Redis Configuration ================
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# ================ Advanced Configuration ================
# Debug mode (more verbose logging)
DEBUG=false

# Logging
DEFAULT_LOG=true
LOG_PATH=logs/ai-researcher.log

# Evaluation mode
EVAL_MODE=false

# Function calling support
FN_CALL=true

# Add user role to messages (required for some models)
ADD_USER=false

# ================ Performance Tuning ================
# Maximum worker threads
MAX_WORKERS=4

# Request timeout (seconds)
TIMEOUT=300

# Retry attempts for failed requests
RETRY_ATTEMPTS=3

# Rate limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD=60

# ================ Monitoring (Optional) ================
# Grafana admin password
GRAFANA_PASSWORD=admin

# ================ Notes & Security Best Practices ================
# 1. üîí NEVER commit .env file to git (it's in .gitignore)
# 2. üîë Keep API keys secret - don't share with anyone
# 3. üí∞ Set rate limits to control costs
# 4. üîÑ Rotate API keys regularly
# 5. üìä Monitor API usage on provider dashboards
# 6. üõ°Ô∏è Use separate API keys for development and production
# 7. üíæ Backup .env file securely (e.g., password manager)

# ================ Quick Model Selection Guide ================
#
# üåü Z.AI (Recommended for Chinese users):
#   - glm-4.6: Best quality, most expensive
#   - glm-4-flashx: Faster, cheaper
#   - Great for Chinese language tasks
#
# üåê OpenRouter (Most flexible):
#   - Access to 100+ models with one API key
#   - Automatic failover between providers
#   - Good pricing, pay-per-use
#
# ü§ñ OpenAI (Best for English):
#   - gpt-4o: Best quality
#   - gpt-4o-mini: Fast and cheap
#   - o1-preview: Best reasoning
#
# üß† Anthropic (Best for long context):
#   - claude-3-5-sonnet: Balanced quality/cost
#   - claude-3-5-opus: Highest quality
#   - claude-3-5-haiku: Fastest, cheapest
#
# üîç DeepSeek (Best for coding):
#   - deepseek-chat: General purpose
#   - deepseek-coder: Optimized for code
#   - Very competitive pricing

# ================ Example Configurations ================
#
# Example 1: Z.AI Setup
# ZAI_API_KEY=your_actual_key
# COMPLETION_MODEL=glm-4.6
# CHEEP_MODEL=glm-4-flashx
#
# Example 2: OpenRouter Multi-Model
# OPENROUTER_API_KEY=your_actual_key
# COMPLETION_MODEL=openrouter/google/gemini-2.5-pro-preview-05-20
# CHEEP_MODEL=openrouter/google/gemini-2.5-flash-preview-05-20
#
# Example 3: OpenAI + Anthropic
# OPENAI_API_KEY=your_actual_openai_key
# ANTHROPIC_API_KEY=your_actual_anthropic_key
# COMPLETION_MODEL=claude-3-5-sonnet-20241022
# CHEEP_MODEL=gpt-4o-mini
#
# Example 4: Cost-Optimized
# OPENROUTER_API_KEY=your_actual_key
# COMPLETION_MODEL=openrouter/google/gemini-2.5-flash-preview-05-20
# CHEEP_MODEL=openrouter/google/gemini-2.5-flash-preview-05-20

# ================ API Key Validation ================
# Run this to validate your setup:
#   python -c "from utils.secrets_manager import get_secrets; get_secrets().validate_all_required_secrets()"
