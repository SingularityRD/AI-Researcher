# ğŸ“š AI-Researcher KullanÄ±m KÄ±lavuzu

> **HÄ±zlÄ±, kolay ve production-ready AI-destekli araÅŸtÄ±rma platformu**

---

## ğŸ“‘ Ä°Ã§indekiler

1. [HÄ±zlÄ± BaÅŸlangÄ±Ã§](#hÄ±zlÄ±-baÅŸlangÄ±Ã§)
2. [Kurulum YÃ¶ntemleri](#kurulum-yÃ¶ntemleri)
3. [Temel KullanÄ±m](#temel-kullanÄ±m)
4. [NeurIPS-Tier Paper YazÄ±mÄ±](#neurips-tier-paper-yazÄ±mÄ±)
5. [Ä°leri Seviye KullanÄ±m](#ileri-seviye-kullanÄ±m)
6. [Makefile KomutlarÄ±](#makefile-komutlarÄ±)
7. [Sorun Giderme](#sorun-giderme)
8. [SÄ±k Sorulan Sorular](#sÄ±k-sorulan-sorular)

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### ğŸ¨ En Kolay YÃ¶ntem: Web GUI (Terminal Bilgisi Gerektirmez!)

**Grafiksel arayÃ¼z tercih edenler iÃ§in:**

```bash
# 1. Projeyi klonla
git clone https://github.com/HKUDS/AI-Researcher.git
cd AI-Researcher

# 2. Environment dosyasÄ±nÄ± hazÄ±rla
cp .env.example .env
nano .env  # API anahtarlarÄ±nÄ± ekle

# 3. Web GUI'yi baÅŸlat
make up
make webgui
```

**TarayÄ±cÄ±da aÃ§:** http://localhost:7860 ğŸ‰

**Web GUI Ã–zellikleri:**
- âœ… **GÃ¶rsel ArayÃ¼z** - Terminal bilgisi gerektirmez!
- âœ… **Kolay KonfigÃ¼rasyon** - API anahtarlarÄ± ve parametreleri UI'da ayarla
- âœ… **Task SeÃ§imi** - Ã–rnek tasklar veya kendi araÅŸtÄ±rmanÄ± seÃ§
- âœ… **CanlÄ± Loglar** - AraÅŸtÄ±rma ilerlemesini gerÃ§ek zamanlÄ± izle
- âœ… **Paper Ä°ndirme** - OluÅŸturulan paper'larÄ± direkt indir
- âœ… **Modern ArayÃ¼z** - Gradio ile responsive tasarÄ±m

### ğŸ–¥ï¸ Alternatif: Komut SatÄ±rÄ± (Ä°leri KullanÄ±cÄ±lar)

```bash
# 1. Projeyi klonla
git clone https://github.com/HKUDS/AI-Researcher.git
cd AI-Researcher

# 2. Environment dosyasÄ±nÄ± hazÄ±rla
cp .env.example .env
# .env dosyasÄ±nÄ± dÃ¼zenle ve API anahtarlarÄ±nÄ± ekle

# 3. Her ÅŸeyi baÅŸlat!
make up

# 4. Health check
make health
```

**Tebrikler! ğŸ‰** AI-Researcher Ã§alÄ±ÅŸÄ±yor.

- ğŸ¨ **Web GUI:** http://localhost:7860
- ğŸ¥ **Health API:** http://localhost:8000/health

---

## ğŸ”§ Kurulum YÃ¶ntemleri

### YÃ¶ntem 1: Docker Compose (Ã–nerilen - Production Ready)

**Gereksinimler:**
- Docker Desktop veya Docker Engine
- Docker Compose
- En az 8GB RAM
- (Opsiyonel) NVIDIA GPU + nvidia-docker

**Kurulum:**

```bash
# Repository'yi klonla
git clone https://github.com/HKUDS/AI-Researcher.git
cd AI-Researcher

# Environment yapÄ±landÄ±r
cp .env.example .env
nano .env  # veya vim, code, vs.
```

**.env DosyasÄ± KonfigÃ¼rasyonu:**

```bash
# ================ LLM Configuration ================
# OpenRouter (Ã–nerilen - birÃ§ok model destekler)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# Veya OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# Veya Anthropic Claude
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Veya DeepSeek (Ucuz ve iyi!)
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_API_BASE=https://api.deepseek.com

# ================ Model Selection ================
# Completion model (ana iÅŸlemler iÃ§in)
COMPLETION_MODEL=openrouter/google/gemini-2.5-pro-preview-05-20
# veya
# COMPLETION_MODEL=gpt-4o
# COMPLETION_MODEL=claude-3-5-sonnet-20241022
# COMPLETION_MODEL=deepseek/deepseek-chat

# Cheap model (basit iÅŸlemler iÃ§in)
CHEEP_MODEL=openrouter/google/gemini-2.5-flash-preview-05-20

# ================ GPU Configuration ================
# GPU kullanÄ±mÄ± (varsa)
GPUS='"device=0"'       # Ä°lk GPU
# GPUS='"device=0,1"'   # Ä°lk iki GPU
# GPUS='"all"'          # TÃ¼m GPU'lar
# GPUS=None             # GPU yok

# ================ Task Configuration ================
CATEGORY=vq              # veya: gnn, reasoning, recommendation, diffu_flow
INSTANCE_ID=rotation_vq  # benchmark instance
TASK_LEVEL=task1         # task1 veya task2
MAX_ITER_TIMES=0

# ================ Performance Settings ================
# Redis cache (performans iÃ§in)
REDIS_ENABLED=true
REDIS_HOST=redis
REDIS_PORT=6379

# Paper quality thresholds
QUALITY_THRESHOLD=0.75   # 0.75=Accept, 0.85=Spotlight
MAX_ITERATIONS=3         # Quality enhancement iterations
```

**Docker Compose ile BaÅŸlat:**

```bash
# Servisleri baÅŸlat
docker-compose up -d

# LoglarÄ± izle
docker-compose logs -f

# Health check
curl http://localhost:8000/health

# Durdur
docker-compose down
```

### YÃ¶ntem 2: Makefile ile (En Kolay)

```bash
# YardÄ±m - tÃ¼m komutlarÄ± gÃ¶r
make help

# Setup ve baÅŸlat
make setup
make start

# Research Ã§alÄ±ÅŸtÄ±r
make run-research CATEGORY=vq INSTANCE=rotation_vq

# Paper yaz (NeurIPS-tier)
make run-enhanced-paper CATEGORY=vq INSTANCE=rotation_vq

# Health check
make health

# Logs
make logs
```

### YÃ¶ntem 3: run.sh Script (En Pratik)

```bash
# Executable yap
chmod +x run.sh

# Setup
./run.sh setup

# BaÅŸlat
./run.sh start

# Health check
./run.sh health

# Durdur
./run.sh stop

# Logs
./run.sh logs

# Temizle
./run.sh clean
```

### YÃ¶ntem 4: Manuel Python (Development)

```bash
# UV ile environment kur (hÄ±zlÄ±!)
curl -LsSf https://astral.sh/uv/install.sh | sh
source ~/.bashrc

# Environment oluÅŸtur
uv venv --python 3.11
source ./.venv/bin/activate

# Dependencies yÃ¼kle
uv pip install -e .
playwright install

# Ã‡alÄ±ÅŸtÄ±r
python research_agent/run_infer_plan.py \
  --instance_path benchmark/final/vq/rotation_vq.json \
  --container_name paper_eval \
  --task_level task1 \
  --model gpt-4o
```

---

## ğŸ“– Temel KullanÄ±m

### ğŸ¨ Web GUI ile KullanÄ±m (Ã–NERÄ°LEN!)

#### BaÅŸlatma

```bash
# TÃ¼m servisleri baÅŸlat
make up

# Web GUI'yi aÃ§
make webgui
```

**TarayÄ±cÄ±da:** http://localhost:7860

#### Web GUI KullanÄ±mÄ±

![Web GUI Ana Ekran](./assets/webgui/image-20250606135137558.png)

**1. Environment AyarlarÄ±**

![Environment Config](./assets/webgui/image-20250606135325373.png)

Environment sekmesinde:
- âœ… **API Keys** - OpenRouter, OpenAI, Anthropic API anahtarlarÄ±
- âœ… **Model Selection** - Completion ve cheap model seÃ§imi
- âœ… **GPU Settings** - GPU konfigÃ¼rasyonu
- âœ… **Task Settings** - Category, instance ID, task level

**2. Task SeÃ§imi**

![Task Selection](./assets/webgui/image-20250606135507970.png)

- **Ã–rnek Tasklar** - HazÄ±r Ã¶rneklerden seÃ§:
  - Vector Quantization (VQ)
  - Graph Neural Networks (GNN)
  - Recommendation Systems
  - Diffusion & Flow Matching
  - Reasoning

- **Custom Task** - Kendi araÅŸtÄ±rmanÄ± tanÄ±mla:
  - Category seÃ§
  - Instance ID gir
  - Task level belirle (task1/task2)
  - Research idea yaz (Level 1)
  - Veya sadece papers ver (Level 2)

**3. Research BaÅŸlat**

1. Environment ayarlarÄ±nÄ± yapÄ±landÄ±r
2. Task'Ä± seÃ§ veya custom task oluÅŸtur
3. "Start Research" butonuna bas
4. CanlÄ± loglarÄ± izle

**4. Ä°lerlemeyi Ä°zle**

Web GUI'de real-time:
- âœ… Log Ã§Ä±ktÄ±larÄ±
- âœ… Durum gÃ¼ncellemeleri
- âœ… Hata mesajlarÄ± (varsa)
- âœ… Tamamlanma yÃ¼zdesi

**5. Paper Ä°ndir**

Research tamamlandÄ±ÄŸÄ±nda:
- âœ… "Generate Paper" butonuna bas
- âœ… Paper oluÅŸmasÄ± iÃ§in bekle
- âœ… "Download PDF" ile indir

#### Web GUI KomutlarÄ±

```bash
# Web GUI baÅŸlat
make webgui

# LoglarÄ± gÃ¶rÃ¼ntÃ¼le
make webgui-logs

# Yeniden baÅŸlat
make webgui-restart

# Durdur
make webgui-stop
```

#### Remote EriÅŸim

Sunucuda Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z:

```bash
# Sunucuda
make up
make webgui

# Local makinenizde browser'da aÃ§:
http://your-server-ip:7860

# Veya SSH tunnel ile:
ssh -L 7860:localhost:7860 user@your-server
# Sonra local'de: http://localhost:7860
```

---

### ğŸ–¥ï¸ Komut SatÄ±rÄ± ile KullanÄ±m

#### 1. Research Agent Ã‡alÄ±ÅŸtÄ±rma

AI-Researcher iki seviyede Ã§alÄ±ÅŸÄ±r:

#### **Level 1: DetaylÄ± Fikir ile**

Kendi research fikriniz var, implement edilmesini istiyorsunuz:

```bash
# Makefile ile
make run-research \
  CATEGORY=vq \
  INSTANCE=rotation_vq \
  TASK_LEVEL=task1

# Veya doÄŸrudan
python research_agent/run_infer_plan.py \
  --instance_path benchmark/final/vq/rotation_vq.json \
  --container_name paper_eval \
  --task_level task1 \
  --model gpt-4o \
  --workplace_name workplace \
  --cache_path cache \
  --port 12372
```

**Ä°Ã§erir:**
- âœ… Literature review
- âœ… Algorithm design
- âœ… Implementation
- âœ… Experiments
- âœ… Result analysis

#### **Level 2: Sadece Reference Papers ile**

Sadece paper'lar veriyorsunuz, AI kendi fikri Ã¼retiyor:

```bash
# Makefile ile
make run-research \
  CATEGORY=vq \
  INSTANCE=rotation_vq \
  TASK_LEVEL=task2

# Veya doÄŸrudan
python research_agent/run_infer_idea.py \
  --instance_path benchmark/final/vq/rotation_vq.json \
  --container_name paper_eval \
  --model gpt-4o
```

**Ä°Ã§erir:**
- âœ… Reference paper analysis
- âœ… **Automatic idea generation**
- âœ… Implementation
- âœ… Experiments
- âœ… Result analysis

### 2. Paper Yazma

#### Standard Paper Writing

```bash
# Makefile ile
make run-paper CATEGORY=vq INSTANCE=rotation_vq

# Veya doÄŸrudan
python paper_agent/writing.py \
  --research_field vq \
  --instance_id rotation_vq
```

**Ã‡Ä±ktÄ±:**
- ğŸ“„ Full-length academic paper
- ğŸ“Š Figures and tables
- ğŸ“š References
- ğŸ“ LaTeX source

---

## ğŸŒŸ NeurIPS-Tier Paper YazÄ±mÄ±

### Neden Enhanced Paper Writer?

Standard paper writer iyi, ama **Enhanced Paper Writer**:
- ğŸ¯ **NeurIPS/ICML/ICLR standartlarÄ±nda** paper Ã¼retir
- ğŸ“Š **Statistical significance** otomatik ekler
- ğŸ’ª **Strong baselines** ile compare eder
- ğŸ”¬ **Comprehensive ablations** yapar
- ğŸ›¡ï¸ **Hallucination yapmaz** - fake results/citations Ã¼retmez!

### KullanÄ±m

```bash
# En basit (Makefile ile)
make run-enhanced-paper CATEGORY=vq INSTANCE=rotation_vq

# Custom quality threshold ile
make run-enhanced-paper \
  CATEGORY=vq \
  INSTANCE=rotation_vq \
  QUALITY_THRESHOLD=0.85 \
  MAX_ITERATIONS=5

# Quality check
make check-paper-quality CATEGORY=vq INSTANCE=rotation_vq
```

### Quality Tiers

| Skor | Tier | AÃ§Ä±klama |
|------|------|----------|
| **0.85+** | ğŸŒŸ **NeurIPS Spotlight** | Top 5% - Outstanding paper |
| **0.75-0.84** | âœ… **NeurIPS Accept** | Top 20% - Strong paper |
| **0.65-0.74** | ğŸ“ **Workshop/ICLR** | Good paper, needs minor improvements |
| **<0.65** | âš ï¸ **Major Revision** | Significant improvements needed |

### Enhanced Paper Features

#### 1. **Statistical Significance** ğŸ“Š

Otomatik ekler:
- P-values (t-test, Wilcoxon)
- Confidence intervals (95% CI)
- Effect sizes (Cohen's d)
- Multiple runs with different seeds
- Significance indicators (*, **, ***)

**Ã–rnek Ã§Ä±ktÄ±:**
```latex
Method          | Accuracy        | F1-Score        | p-value
----------------|-----------------|-----------------|--------
Baseline 1      | 85.2 Â± 0.3     | 0.652 Â± 0.012  | -
Baseline 2      | 87.1 Â± 0.4     | 0.678 Â± 0.015  | -
Ours           | 89.3 Â± 0.2***  | 0.712 Â± 0.008***| <0.001
```

#### 2. **Strong Baselines** ğŸ’ª

Otomatik Ã¶neriyor:
- Classic methods (foundational)
- Recent SOTA (2023-2024)
- Similar approaches
- Different paradigms

**Ã–rnek:**
```python
Suggested Baselines for VQ-VAE:
1. VQ-VAE (van den Oord et al., 2017) - Classic
2. VQ-VAE-2 (Razavi et al., 2019) - Hierarchical
3. FSQ (Mentzer et al., 2023) - Recent SOTA
4. RQ-VAE (Lee et al., 2022) - Different paradigm
```

#### 3. **Comprehensive Ablations** ğŸ”¬

Otomatik generate eder:
- Component ablations (her component iÃ§in)
- Design choice ablations
- Hyperparameter sensitivity
- Architecture variants

**Ã–rnek:**
```latex
\subsection{Ablation Studies}

Component         | Accuracy | Î”
------------------|----------|----
Full Model        | 89.3     | -
- Rotation        | 85.1     | -4.2
- Rescaling       | 87.2     | -2.1
- Codebook Mgmt   | 86.5     | -2.8
```

#### 4. **Hallucination Prevention** ğŸ›¡ï¸

**Problem:** LLM'ler fake results/citations/theorems Ã¼retebilir!

**Ã‡Ã¶zÃ¼m:** Strict validation rules:

```python
âš ï¸ ANTI-HALLUCINATION RULES:
1. NEVER fabricate experimental results
   âŒ "Achieves 94.7% accuracy" (data yoksa)
   âœ… "Achieves significant improvement (see Table 2)"

2. NEVER make up citations
   âŒ "As shown by Johnson et al. (2024)" (paper yoksa)
   âœ… "[Citation Needed: recent transformer work]"

3. NEVER claim unproven theorems
   âŒ "We prove that complexity is O(n)"
   âœ… "We conjecture that complexity is O(n) [REQUIRES PROOF]"

4. NEVER fabricate baselines
   âŒ Invents fake baseline results
   âœ… Uses only provided baseline data

5. GROUND ALL STATEMENTS
   âœ… Every number from actual experiments
   âœ… Every claim backed by results
```

**Otomatik Validation:**
```python
# Hallucination detection
warnings = validate_for_hallucination(
    content=generated_paper,
    allowed_numbers=experimental_results
)

# Checks:
âœ“ Unexpected numbers not in data
âœ“ Suspiciously precise results
âœ“ Generic citations ("Smith et al., 2024")
âœ“ Ungrounded claims
âœ“ Placeholder markers
```

#### 5. **Iterative Enhancement** ğŸ”„

```python
# Enhancement loop
while quality_score < threshold and iteration < max_iterations:
    # 1. Check quality
    score, report = check_quality(paper)

    # 2. Identify weak sections
    weak_sections = find_weak_sections(report)

    # 3. Enhance sections
    for section in weak_sections:
        if section == "experiments":
            add_statistical_significance()
            enhance_ablations()
        elif section == "contributions":
            improve_clarity()
            add_evidence()
        elif section == "related_work":
            expand_coverage()
            add_critical_analysis()

    # 4. Re-check quality
    iteration += 1

# 5. Final enhancements
add_limitations_section()
add_reproducibility_statement()
add_broader_impact()
```

### Quality Report Ã–rneÄŸi

```
=====================================
PAPER QUALITY REPORT
=====================================

Overall Score: 0.82/1.00
Tier: NeurIPS/ICML Accept (Top 20%)

DETAILED SCORES:
Contributions: 0.85/1.00
  âœ“ Clear novelty statement
  âœ“ Well-positioned vs prior work
  âš  Could strengthen impact discussion

Methodology: 0.78/1.00
  âœ“ Mathematical rigor present
  âœ“ Algorithm well-described
  âš  Missing complexity analysis

Experiments: 0.88/1.00
  âœ“ Strong baselines
  âœ“ Statistical significance
  âœ“ Comprehensive ablations
  âœ“ Multiple datasets

Related Work: 0.75/1.00
  âœ“ Good coverage (18 papers)
  âš  Could add more critical analysis

Writing: 0.82/1.00
  âœ“ Clear and concise
  âœ“ Good flow
  âœ“ Consistent notation

Ethics: 0.90/1.00
  âœ“ Limitations discussed
  âœ“ Reproducibility info
  âœ“ Broader impact

RECOMMENDATIONS:
âœ“ GOOD QUALITY - Minor improvements suggested
- Add complexity analysis to methodology
- Strengthen contribution impact discussion
- Expand critical analysis in related work
```

---

## ğŸ¯ Ä°leri Seviye KullanÄ±m

### Custom Benchmarks

Kendi benchmark'Ä±nÄ±zÄ± ekleyin:

```bash
# 1. Benchmark dosyasÄ± oluÅŸtur
mkdir -p benchmark/final/my_domain
nano benchmark/final/my_domain/my_task.json
```

```json
{
  "task_id": "my_task",
  "category": "my_domain",
  "description": "Task description",
  "idea": "Detailed implementation idea...",
  "reference_papers": [
    {
      "title": "Paper 1",
      "authors": ["Author 1", "Author 2"],
      "year": 2024,
      "abstract": "..."
    }
  ]
}
```

```bash
# 2. Ã‡alÄ±ÅŸtÄ±r
make run-research CATEGORY=my_domain INSTANCE=my_task
```

### Multi-GPU Setup

```bash
# .env dosyasÄ±nda
GPUS='"device=0,1,2,3"'  # 4 GPU kullan

# Veya docker-compose.yml'de
services:
  ai-researcher:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
```

### Custom Model Configuration

```bash
# .env dosyasÄ±nda farklÄ± provider'lar

# OpenRouter (Ã§ok model seÃ§eneÄŸi)
OPENROUTER_API_KEY=...
COMPLETION_MODEL=openrouter/google/gemini-2.5-pro-preview-05-20
CHEEP_MODEL=openrouter/google/gemini-2.5-flash-preview-05-20

# DeepSeek (ucuz ve iyi!)
DEEPSEEK_API_KEY=...
COMPLETION_MODEL=deepseek/deepseek-chat
CHEEP_MODEL=deepseek/deepseek-chat

# OpenAI
OPENAI_API_KEY=...
COMPLETION_MODEL=gpt-4o
CHEEP_MODEL=gpt-4o-mini

# Anthropic
ANTHROPIC_API_KEY=...
COMPLETION_MODEL=claude-3-5-sonnet-20241022
CHEEP_MODEL=claude-3-5-haiku-20241022

# Local LLM (Ollama)
LLM_BASE_URL=http://localhost:11434
COMPLETION_MODEL=ollama/llama3.1:70b
CHEEP_MODEL=ollama/llama3.1:8b
```

### Parallel Research

Birden fazla research paralel Ã§alÄ±ÅŸtÄ±r:

```bash
# Terminal 1
make run-research CATEGORY=vq INSTANCE=rotation_vq PORT=12372

# Terminal 2
make run-research CATEGORY=gnn INSTANCE=nodeformer PORT=12373

# Terminal 3
make run-research CATEGORY=recommendation INSTANCE=hgcl PORT=12374
```

### Monitoring ve Health Checks

```bash
# Health API endpoints
curl http://localhost:8000/health    # Full health check
curl http://localhost:8000/ready     # Readiness check
curl http://localhost:8000/ping      # Simple ping

# Metrics
curl http://localhost:8000/health | jq .
{
  "status": "healthy",
  "checks": {
    "api": true,
    "memory": true,
    "disk": true,
    "cpu": true,
    "redis": true
  },
  "metrics": {
    "memory_percent": 45.2,
    "disk_percent": 68.1,
    "cpu_percent": 23.5
  },
  "timestamp": "2025-01-15T10:30:00Z"
}
```

---

## ğŸ› ï¸ Makefile KomutlarÄ±

### Setup ve Management

```bash
make help                 # TÃ¼m komutlarÄ± gÃ¶ster
make setup               # Ä°lk kurulum (build + env check)
make start               # Servisleri baÅŸlat
make stop                # Servisleri durdur
make restart             # Yeniden baÅŸlat
make clean               # Temizle (containers, volumes, cache)
make build               # Docker image build et
make rebuild             # Force rebuild
```

### Research Operations

```bash
make run-research        # Research agent Ã§alÄ±ÅŸtÄ±r
  CATEGORY=vq           # Category seÃ§
  INSTANCE=rotation_vq  # Instance seÃ§
  TASK_LEVEL=task1     # Task level (task1/task2)
  MODEL=gpt-4o         # Model override

make run-paper          # Standard paper yaz
  CATEGORY=vq
  INSTANCE=rotation_vq

make run-enhanced-paper     # NeurIPS-tier paper yaz (Ã¶nerilen!)
  CATEGORY=vq
  INSTANCE=rotation_vq
  QUALITY_THRESHOLD=0.75   # Quality threshold
  MAX_ITERATIONS=3         # Max enhancement iterations

make check-paper-quality    # Paper quality kontrolÃ¼
  CATEGORY=vq
  INSTANCE=rotation_vq
```

### Monitoring

```bash
make health              # Health check
make logs                # LoglarÄ± gÃ¶ster
make logs-follow         # LoglarÄ± takip et (real-time)
make ps                  # Running containers
make stats               # Resource usage stats
```

### Development

```bash
make shell               # Container shell aÃ§
make test                # Testleri Ã§alÄ±ÅŸtÄ±r
make lint                # Code quality check
make format              # Code formatting
```

### Examples

```bash
make example-vq          # VQ example Ã§alÄ±ÅŸtÄ±r
make example-gnn         # GNN example Ã§alÄ±ÅŸtÄ±r
make example-rec         # Recommendation example
make example-all         # TÃ¼m examples (paralel)
```

---

## ğŸ” Sorun Giderme

### SÄ±k KarÅŸÄ±laÅŸÄ±lan Sorunlar

#### 1. **Docker Container BaÅŸlamÄ±yor**

**Semptom:**
```bash
Error: Cannot connect to the Docker daemon
```

**Ã‡Ã¶zÃ¼m:**
```bash
# Docker'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol et
sudo systemctl status docker

# Docker'Ä± baÅŸlat
sudo systemctl start docker

# User'Ä± docker grubuna ekle (sudo olmadan kullanmak iÃ§in)
sudo usermod -aG docker $USER
newgrp docker
```

#### 2. **GPU TanÄ±nmÄ±yor**

**Semptom:**
```bash
docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].
```

**Ã‡Ã¶zÃ¼m:**
```bash
# NVIDIA Docker runtime kur
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker

# Test et
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
```

#### 3. **API Key HatasÄ±**

**Semptom:**
```bash
Error: API key not configured
```

**Ã‡Ã¶zÃ¼m:**
```bash
# .env dosyasÄ±nÄ± kontrol et
cat .env | grep API_KEY

# API key ekle
nano .env
# OPENROUTER_API_KEY=your_actual_key_here

# Container'Ä± yeniden baÅŸlat
make restart
```

#### 4. **Port Conflict**

**Semptom:**
```bash
Error: Bind for 0.0.0.0:8000 failed: port is already allocated
```

**Ã‡Ã¶zÃ¼m:**
```bash
# Portu kullanan process'i bul
sudo lsof -i :8000

# Process'i kapat veya .env'de portu deÄŸiÅŸtir
# PORT=8001

# Veya docker-compose.yml'de
ports:
  - "8001:8000"
```

#### 5. **Memory HatasÄ±**

**Semptom:**
```bash
Error: Container killed (OOM)
```

**Ã‡Ã¶zÃ¼m:**
```bash
# Docker'a daha fazla memory ver
# Docker Desktop â†’ Settings â†’ Resources â†’ Memory â†’ 8GB+

# Veya docker-compose.yml'de limit artÄ±r
services:
  ai-researcher:
    deploy:
      resources:
        limits:
          memory: 8G
```

#### 6. **Redis Connection HatasÄ±**

**Semptom:**
```bash
Error: Could not connect to Redis
```

**Ã‡Ã¶zÃ¼m:**
```bash
# Redis container'Ä±nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol et
docker-compose ps

# Redis'i yeniden baÅŸlat
docker-compose restart redis

# Veya .env'de Redis'i devre dÄ±ÅŸÄ± bÄ±rak
REDIS_ENABLED=false
```

### Debug Mode

```bash
# Verbose logging
export DEBUG=true
make run-research CATEGORY=vq INSTANCE=rotation_vq

# Container iÃ§inde debug
docker-compose exec ai-researcher bash
python -m pdb research_agent/run_infer_plan.py ...
```

### Log Analizi

```bash
# TÃ¼m loglarÄ± gÃ¶r
make logs

# Son 100 satÄ±r
docker-compose logs --tail=100

# Specific service
docker-compose logs ai-researcher

# Real-time follow
docker-compose logs -f

# Grep ile filtrele
docker-compose logs | grep ERROR
```

---

## â“ SÄ±k Sorulan Sorular (FAQ)

### Genel

**Q: AI-Researcher Ã¼cretsiz mi?**
A: Evet, AI-Researcher aÃ§Ä±k kaynak ve Ã¼cretsiz. Sadece kullandÄ±ÄŸÄ±nÄ±z LLM API'leri iÃ§in Ã¶deme yaparsÄ±nÄ±z (OpenAI, Anthropic, vs.)

**Q: Hangi LLM provider'Ä± Ã¶neriyorsunuz?**
A:
- **En iyi kalite:** Claude 3.5 Sonnet (Anthropic) veya GPT-4o (OpenAI)
- **En ucuz:** DeepSeek Chat (Ã§ok iyi ve ucuz!)
- **En Ã§ok seÃ§enek:** OpenRouter (100+ model)

**Q: GPU ÅŸart mÄ±?**
A: HayÄ±r, ama bÃ¼yÃ¼k experiments iÃ§in Ã¶nerilir. CPU ile de Ã§alÄ±ÅŸÄ±r.

**Q: KaÃ§ sÃ¼rede paper yazÄ±lÄ±r?**
A: Complexity'e baÄŸlÄ±:
- Simple task: 2-4 saat
- Medium task: 6-12 saat
- Complex task: 24-48 saat

### Research

**Q: Level 1 ve Level 2 farkÄ± nedir?**
A:
- **Level 1:** Fikir VERÄ°YORSUNUZ â†’ Implementation + Experiments
- **Level 2:** Sadece papers VERÄ°YORSUNUZ â†’ Idea generation + Implementation + Experiments

**Q: Kendi dataset'imi kullanabilir miyim?**
A: Evet! Benchmark format'Ä±nda JSON dosyasÄ± oluÅŸturun.

**Q: Research durdurup devam edebilir miyim?**
A: Evet, `MAX_ITER_TIMES` ayarÄ±nÄ± kullanarak checkpoint'lerden devam edebilirsiniz.

### Paper Writing

**Q: Standard vs Enhanced paper writer farkÄ±?**
A:
- **Standard:** Basic paper generation
- **Enhanced:** NeurIPS-tier quality + statistical significance + strong baselines + ablations + hallucination prevention

**Q: Enhanced paper writer iÃ§in ekstra Ã¼cret var mÄ±?**
A: HayÄ±r, sadece daha fazla LLM API call yapÄ±yor (daha fazla iteration).

**Q: Hallucination prevention nasÄ±l Ã§alÄ±ÅŸÄ±yor?**
A: Her prompt'ta strict validation rules + otomatik number/citation checking + conservative language.

**Q: Paper'Ä± dÃ¼zenleyebilir miyim?**
A: Evet! LaTeX source output'u dÃ¼zenleyebilirsiniz.

### Web GUI

**Q: Web GUI vs Komut SatÄ±rÄ± - Hangisini kullanmalÄ±yÄ±m?**
A:
- **Web GUI:** Terminal bilgisi gerektirmez, gÃ¶rsel arayÃ¼z, baÅŸlangÄ±Ã§ iÃ§in ideal
- **Komut SatÄ±rÄ±:** Otomasyon, scripting, ileri kullanÄ±cÄ±lar iÃ§in

**Q: Web GUI port'unu deÄŸiÅŸtirebilir miyim?**
A: Evet! `.env` dosyasÄ±nda `WEBGUI_PORT=7860` deÄŸerini deÄŸiÅŸtirin.

**Q: Web GUI'ye uzaktan eriÅŸebilir miyim?**
A: Evet! Ä°ki yÃ¶ntem:
1. Direkt: `http://server-ip:7860`
2. SSH tunnel: `ssh -L 7860:localhost:7860 user@server`

**Q: Web GUI Ã§alÄ±ÅŸmÄ±yor, ne yapmalÄ±yÄ±m?**
A:
```bash
# LoglarÄ± kontrol et
make webgui-logs

# Yeniden baÅŸlat
make webgui-restart

# Port kullanÄ±mda olabilir
sudo lsof -i :7860
```

**Q: Web GUI'de API key deÄŸiÅŸtirsem Docker restart gerekli mi?**
A: HayÄ±r! Web GUI'de environment sekmesinden direkt deÄŸiÅŸtirebilirsiniz.

**Q: Web GUI ile birden fazla research paralel Ã§alÄ±ÅŸtÄ±rabilir miyim?**
A: Åu an tek research destekleniyor. Paralel iÃ§in komut satÄ±rÄ±nÄ± kullanÄ±n.

### Teknik

**Q: Hangi Python versiyonu?**
A: Python 3.11 (uv ile otomatik kurulur)

**Q: Windows'ta Ã§alÄ±ÅŸÄ±r mÄ±?**
A: Evet, Docker Desktop ile. WSL2 Ã¶nerilir.

**Q: M1/M2 Mac destekliyor mu?**
A: Evet! Platform: linux/arm64 kullanÄ±n.

**Q: Redis neden gerekli?**
A: Caching iÃ§in. Opsiyonel, ama performansÄ± 2-3x artÄ±rÄ±r.

**Q: Proxy arkasÄ±nda kullanabilir miyim?**
A: Evet, `HTTP_PROXY` ve `HTTPS_PROXY` environment variables ayarlayÄ±n.

---

## ğŸ“ Destek ve Topluluk

### YardÄ±m AlabileceÄŸiniz Yerler

- ğŸ“– **DokÃ¼mantasyon:** [https://autoresearcher.github.io/docs](https://autoresearcher.github.io/docs)
- ğŸ’¬ **Slack:** [AI-Researcher Community](https://join.slack.com/t/ai-researchergroup/shared_invite/zt-30y5a070k-C0ajQt1zmVczFnfGkIicvA)
- ğŸ® **Discord:** [Join Discord](https://discord.gg/zBNYTk5q2g)
- ğŸ› **GitHub Issues:** [Report Issue](https://github.com/HKUDS/AI-Researcher/issues)
- ğŸ“§ **Email:** [Contact](mailto:jtang@connect.hku.hk)

### KatkÄ±da Bulunma

```bash
# 1. Fork edin
# 2. Feature branch oluÅŸturun
git checkout -b feature/amazing-feature

# 3. Commit edin
git commit -m "Add amazing feature"

# 4. Push edin
git push origin feature/amazing-feature

# 5. Pull Request aÃ§Ä±n
```

---

## ğŸ“š Ek Kaynaklar

- ğŸ“„ **Paper:** [arXiv:2505.18705](https://arxiv.org/abs/2505.18705)
- ğŸŒ **Project Page:** [https://autoresearcher.github.io](https://autoresearcher.github.io)
- ğŸ“Š **Leaderboard:** [https://autoresearcher.github.io/leaderboard](https://autoresearcher.github.io/leaderboard)
- ğŸ“– **Full Documentation:** [https://autoresearcher.github.io/docs](https://autoresearcher.github.io/docs)
- ğŸš€ **Quickstart:** [QUICKSTART.md](./QUICKSTART.md)
- ğŸ“ **Paper Quality Guide:** [PAPER_IMPROVEMENTS.md](./PAPER_IMPROVEMENTS.md)
- ğŸ› ï¸ **Production Setup:** [IMPROVEMENTS.md](./IMPROVEMENTS.md)

---

## ğŸ‰ Ä°yi AraÅŸtÄ±rmalar!

SorularÄ±nÄ±z iÃ§in:
- Slack/Discord topluluÄŸumuza katÄ±lÄ±n
- GitHub issue aÃ§Ä±n
- DokÃ¼mantasyonu okuyun

**Happy Researching! ğŸš€**
